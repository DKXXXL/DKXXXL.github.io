Ref
1. Algebraic models of dependent type theory https://arxiv.org/pdf/2103.06155.pdf
2. Nat Model https://arxiv.org/pdf/1406.3219.pdf
3. Uemura Thesis https://eprints.illc.uva.nl/id/eprint/2195/1/DS-2021-09.text.pdf 
4. A General Framework for the Semantics of Type Theory https://arxiv.org/pdf/1904.04097.pdf
5. Towards a geometry for syntax https://arxiv.org/pdf/2307.09497.pdf
6. Controlling unfolding in type theory  https://arxiv.org/pdf/2210.05420.pdf
7. Syntax and semantics of modal type theory https://www.danielgratzer.com/papers/phd-thesis.pdf 
8. internal sconing https://arxiv.org/pdf/2302.05190.pdf
9. JS Thesis
 

# Natural Model as Cat Syntax

To properly use Natural Model as Categorical Syntax and achieve HOAS syntax, we need to understand the following
1. extend Natural Model with new type/term former 
  1. via using HOAS signature (Ref 3, Ref 4)
  2. via giving new concrete categorical construction (Ref 1, Ref 2)
  3. for 1, we still need to sort out the concrete cat construction
2. construct specific Natural Model (to possibly construct consistency/canonicity/normalization model)
  1. stable class of maps (Ref 2)
  2. Local Universe Construction, "Promoting universe to a model" (Ref 5, Ref 6, Ref 7) 
3. Free Natural Model
  1. so that for 1, we can construct syntactic nat model using especially 1.1 (Ref 1, Ref 3, Ref 4)
  2. and connect 1 and 2 (Ref 5, Ref 7)
4. Model Morphism on the nose (Ref 5, Ref 7)
  1. For example, if we have syntax `ğ’®.âŠ¥`, and we have construct a consistency (set) model `â„³.âŠ¥ = âˆ…`,
  2. then by freeness, we have `F : ğ’® â†’ â„³`, but we have to have `F(ğ’®.âŠ¥) = â„³.âŠ¥` to achieve the proof of consistency
  3. When I say on the nose, I still mean in HOAS syntax, e.g., compute the morphism result `F(Î» x. y)` using morphism `F` on a lambda term using HOAS syntax (Ref 8) (Ref 1, Lemma 2.3.18) 
     1. or at least be able to compute `F(bool)` and `F(Î  A B)` at type level because they are where motives store
     2. we have this in (Ref 9), because (Ref 9, 1.4âˆ—10, Â§3.7), we need something similar for nat model


The ultimate goal is remove all/most substitution lemma verification in model construction.

****
# Apparent Alternative : Make it first order

Nat Model is equivalent to CwF in first order form, actually (Ref 1, Â§ 2.2) already shows it. 

## Can we just generate the first order (GAT/EAT) specification from HOAS spec?

Yes, because (Ref 1, Â§ 2.2) uses essential algebraic theory. 
We can also use QIIT, intuitively each line of signature corresponds to a line in QIIT spec.

Then we have free Nat Model and Nat Model homomorphism, preserving stuff on the nose. 

The final problem is how to construct the consistency/canonicity model via HOAS/Nat Model without 
verifying subst lemma. (i.e. 2 in the above)

***

# Nat Model in (Ref 7)
Basically, (Ref 7, Lemma 4.3.2) says
> Lemma 4.3.2. (Tyâˆ—,Tmâˆ—) is closed under dependent products
> Proof. Unfolding the statement of this lemma, we must construct terms ..

Basically it is a good news that, the definition of "closed under dependent product" directly unfold to the two constants;
similar for boolean type. (Similar for Lemma 4.3.3). 

But we still need double check about this -- can we directly use constant as the spec in Â§3.4?

## Morphism computation in (Ref 7)

In (Ref 9), we have the `Mod(ğ•Š, â„°) â‰… LCCC(T/ğ•Š, â„°)`, to make sure we can compute the LCCC functor according to ğ•Š-algebra (Ref 9, Â§3.7). We need something similar for nat model. It is in (Ref 7, Def 4.2.1)

<!-- Also the initiality is weird, we have some machinery in (Ref 7, Â§4.2) -->

## Explaining "Structured" Algebra/Model in (Ref 7, Def 4.2.1)
This part/definition is too concise.

1 is actually directly referring to (JS Thesis, Ref 9: 3.2âˆ—2, 3.2âˆ—3, 3.2âˆ—4). The classifying map are actually 
`Sig, Prod : (âˆ‘ (A : Ï„), (A â†’ Ï„)) â†’ Ï„` 

3 is explained very concretely.


## "Structured" Algebra/Model in (Ref 7)



The idea is start with CwF `(ğ’, Ty, Tm ...)`, and change to Nat Model `(ğ’, Ï„ : âˆ‘ Tm â†’ Ty)` for "higher order model" representation.  Note that, the user customized connective are part of the data. (Â§ 3.4).
Note that, the connective can be represented as "high order syntax" at `Psh(ğ’)` level.


Then, we lift the nat model into LCCC level data `(Psh(ğ’), Ï„ : âˆ‘ Tm â†’ Ty)`, where `Ï„` is just an morphism in `Psh(ğ’)`, with those connective inside. Then a model is just a LCCC functor preserve those connective on the nose.

Then thanks to Quasi-projectivity, (Ref 7, Thm 4.2.6), we have a certain level of initiality on this lifted syntax model `(Psh(ğ’), Ï„ : âˆ‘ Tm â†’ Ty)`, where the LCCC functor will make sure preserve type connective on the nose. This Thm 4.2.6 is proved based on the initiality of the initial `CwF` model.

In summary,
1. We start with CwF/Nat Model because its initiality is well-investigated
2. We introduce LCCC Syntax Model solely because we want specify the final consistency/canonicity/normalization model in "higher order spec" to avoid substitution lemma


### Remaining Question
1. There is always a gap between pullback diagram and "Higher Order Model" (in the internal language of presheaf category).
   1. It is specifically written in (Ref 2)
   2. Actually when we really do the proof, we use "Higher Order Model" to close to the formal proof, so we will use less diagram, so it is better we start from higher order model from the beginning
   3. We need to further investigate this paper because we want to add other stuff into the context 
      1. for example, System F needs to have type and term both in the context, but two kinds of stuff
2. Even though we have LCCC functor `ğ¹` strictly preserving operations,
   1. we still need to learn how to do the computation, say `ğ¹(ğ’®.Bool) = â„³.Bool`
   2. we also want this computation at "Higher Order Model" level
      1. basically we only know  `ğ¹` preserves LCCC and those operations (as Ref 7, Definition 4.2.5),
      2. using this information, how to compute `ğ¹(ğ’®.Bool)`, `ğ¹(ğ’®.Î  A B)` and so on?
      3. technically we cannot go back to CwF morphism because it is LCCC functor between two LCCC stuff


***
After these, we can start to consider internalize a Natural Model signature (1.1) inside certain presheaf category.